{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention! To learn more, visit [Nugen](https://docs.nugen.in/introduction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LLM Chain Program**\n",
    "\n",
    "**Program Overview**\n",
    "\n",
    "This program creates a systematic way to solve problems using LLM. Instead of asking the AI to solve a problem all at once, it breaks the solution into steps, similar to how a teacher might guide a student through solving a complex problem. Let's examine each part of the code in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Imports and Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section brings in two essential tools:\n",
    "\n",
    "1. **requests**: This is like a messenger service that lets our program talk to the NuGen AI service over the internet\n",
    "\n",
    "2. **typing**: This helps us write clearer code by specifying what kind of information each part of our program expects (like saying \"this part needs a list of strings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: The run_llm Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(user_prompt: str, \n",
    "            model: str = 'nugen-flash-instruct', \n",
    "            system_prompt: str = None,\n",
    "            api_token: Optional[str] = None,\n",
    "            temperature: float = 0.0,\n",
    "            max_tokens: int = 2000) -> str:\n",
    "  \n",
    "    # Construct the full prompt, incorporating system prompt if provided\n",
    "    full_prompt = f\"{system_prompt + ' ' if system_prompt else ''}{user_prompt}\"\n",
    "    \n",
    "    # Payload for Nugen API\n",
    "    payload = {\n",
    "        \"max_tokens\": str(max_tokens),\n",
    "        \"model\": model,\n",
    "        \"prompt\": full_prompt,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    # Headers with authorization\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Make API request\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.nugen.in/inference/completions\", \n",
    "            json=payload, \n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        # Check for successful response\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse and return the response\n",
    "        response_json = response.json()\n",
    "        return response_json.get('choices', [{}])[0].get('text', '')\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"API Request Error: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is like a translator between your program and the AI service. Let's break down each parameter:\n",
    "\n",
    "1. **user_prompt**: Your question or instruction to the AI\n",
    "\n",
    "2. **model**: The specific AI model to use (defaults to 'nugen-flash-instruct')\n",
    "\n",
    "3. **system_prompt**: Special instructions that set up how the AI should behave\n",
    "\n",
    "4. **api_token**: Your access key to use the AI service\n",
    "\n",
    "5. **temperature**: Controls AI creativity (0.0 means very focused, higher values mean more creative)\n",
    "\n",
    "6. **max_tokens**: Maximum length of the AI's respons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: The serial_chain_workflow Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_chain_workflow(input_query: str, \n",
    "                           prompt_chain: List[str], \n",
    "                           api_token: Optional[str] = None) -> List[str]:\n",
    "    \n",
    "    response_chain = []\n",
    "    response = input_query\n",
    "    \n",
    "    for i, prompt in enumerate(prompt_chain):\n",
    "        print(f\"Step {i+1}\")\n",
    "        \n",
    "        # Run LLM with the current prompt\n",
    "        response = run_llm(\n",
    "            f\"{prompt}\\nInput:\\n{response}\", \n",
    "            api_token=api_token\n",
    "        )\n",
    "        \n",
    "        response_chain.append(response)\n",
    "        print(f\"{response}\\n\")\n",
    "    \n",
    "    return response_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function manages the step-by-step problem-solving process. Think of it as a project manager that:\n",
    "\n",
    "1. Takes your main question\n",
    "2. Has a list of steps to follow\n",
    "3. Goes through each step one at a time\n",
    "4. Uses the answer from each step to help with the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Main Program Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      " (Round to the nearest cent.)\n",
      "Given values and their units:\n",
      "    1. $12/hour\n",
      "    2. 50 minutes\n",
      "What the question is asking for:\n",
      "    1. Sally's earnings\n",
      "Required mathematical operations:\n",
      "    1. Convert minutes to hours\n",
      "    2. Multiply the hourly wage by the number of hours worked\n",
      "    3. Round to the nearest cent\n",
      "\n",
      "Step 2\n",
      "\n",
      "Solution plan:\n",
      "    1. 50 minutes * (1 hour / 60 minutes) = 50/60 hours\n",
      "    2. $12/hour * (50/60) hours = $12 * (50/60)\n",
      "    3. $12 * (50/60) = $10.00\n",
      "\n",
      "Step 3\n",
      "\n",
      "\n",
      "$10.00\n",
      "\n",
      "Final Answer: \n",
      "\n",
      "$10.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example problem\n",
    "    question = \"Sally earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "    \n",
    "    # Prompt chain for step-by-step problem solving\n",
    "    system_prompt = \"\"\"You are a mathematical problem solver. Your task is to solve any given word problem by:\n",
    "        1. Understanding what's given and what's asked\n",
    "        2. Planning the solution approach\n",
    "        3. Executing the calculations accurately\n",
    "        Keep all responses focused ONLY on solving the given problem.\"\"\"\n",
    "\n",
    "    prompt_chain = [\n",
    "    \"\"\"STEP 1 - Description and ANALYSIS:\n",
    "    From the given problem, identify and list ONLY:\n",
    "    1. Given values and their units\n",
    "    2. What the question is asking for\n",
    "    3. Required mathematical operations\n",
    "    NO OTHER INFORMATION OR LISTS ALLOWED.\"\"\",\n",
    "    \n",
    "    \"\"\"STEP 2 - SOLUTION PLAN:\n",
    "    Using the analyzed information, write ONLY:\n",
    "    1. Any needed unit conversions\n",
    "    2. Required formula(s)\n",
    "    3. The equation with actual numbers\n",
    "    NO SOLVING OR EXTRA STEPS.\"\"\",\n",
    "    \n",
    "    \"\"\"STEP 3 - CALCULATION:\n",
    "    Show ONLY:\n",
    "    1. Step-by-step calculations\n",
    "    2. Final answer with appropriate units\n",
    "    NOTHING ELSE ALLOWED.\"\"\"\n",
    "    ]\n",
    "    \n",
    "    # Run the workflow (replace <YOUR_TOKEN> with actual API token)\n",
    "    responses = serial_chain_workflow(question, prompt_chain, api_token=\"nugen-CnStpNdbBczk3d8SZMhmnw\")\n",
    "    \n",
    "    # Print final answer\n",
    "    final_answer = responses[-1]\n",
    "    print(\"Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How The Problem-Solving Process Works\n",
    "Let's see how the program solves the babysitting problem:\n",
    "\n",
    "1. **First Step (Analysis)**: \n",
    "    - The AI identifies the given values ($12/hour, 50 minutes)\n",
    "    - Recognizes what we need to calculate (earnings)\n",
    "    - Lists required operations (time conversion and multiplication)\n",
    "\n",
    "2. **Second Step (Planning)**:\n",
    "\n",
    "    - The AI figures out we need to convert 50 minutes to hours\n",
    "    - Plans to multiply hourly rate by time worked\n",
    "    - Sets up the calculation without solving it\n",
    "\n",
    "3. **Third Step (Calculation)**:\n",
    "\n",
    "    - The AI converts 50 minutes to hours (50/60 = 0.833 hours)\n",
    "    - Multiplies $12 × 0.833\n",
    "    - Provides the final answer with proper units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Flow of Information\n",
    "Information flows through the program like this:\n",
    "\n",
    "- Your question → First prompt → AI → First answer\n",
    "- First answer + Second prompt → AI → Second answer\n",
    "- Second answer + Third prompt → AI → Final answer\n",
    "\n",
    "Each step builds on the previous one, creating a chain of reasoning that leads to the solution.\n",
    "\n",
    "\n",
    "**Common Patterns and Best Practices**\n",
    "When using this program:\n",
    "\n",
    "1. Make your prompts clear and specific\n",
    "2. Break complex problems into logical steps\n",
    "3. Use the system prompt to set the overall approach\n",
    "4. Check each step's output to ensure it makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "This program demonstrates a powerful approach to problem-solving with AI:\n",
    " \n",
    "1. Break down complex problems into steps\n",
    "2. Use clear instructions at each step\n",
    "3. Build on previous answers\n",
    "4. Maintain a clear chain of reasoning\n",
    "\n",
    "The result is a more reliable and understandable problem-solving process than trying to solve everything in one step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
