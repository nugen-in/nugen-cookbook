{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention! To learn more, visit [Nugen](https://docs.nugen.in/introduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Complete Guide to LLM Routing: Concepts and Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Understanding LLM Routing - Core Concepts**\n",
    "\n",
    "**What is LLM Routing?**\n",
    "\n",
    "Think of LLM routing like a skilled receptionist at a hospital. When a patient comes in, the receptionist needs to decide whether to send them to the general physician, the cardiologist, or another specialist. Similarly, LLM routing is the process of directing different types of questions or tasks to the most appropriate AI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Do We Need LLM Routing?**\n",
    "\n",
    "Imagine you have several AI models, each trained for different purposes:\n",
    "\n",
    "One might be excellent at creative writing\n",
    "Another might specialize in legal matters\n",
    "A third might excel at programming tasks\n",
    "\n",
    "Just as you wouldn't want a dermatologist performing heart surgery, you wouldn't want a creative writing model handling legal questions. LLM routing helps ensure each query gets handled by the most qualified model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Code Implementation Explained**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Literal, Dict\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Basic LLM Communication (run_nugen_llm)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nugen_llm(user_prompt: str, model: str, api_token: str, system_prompt: str = None):\n",
    "    \"\"\"\n",
    "    Makes a request to the Nugen API endpoint.\n",
    "    \"\"\"\n",
    "    url = \"https://api.nugen.in/inference/completions\"\n",
    "    \n",
    "    # Combine system prompt and user prompt if system prompt exists\n",
    "    final_prompt = f\"{system_prompt}\\n\\n{user_prompt}\" if system_prompt else user_prompt\n",
    "    \n",
    "    payload = {\n",
    "        \"max_tokens\": \"1000\",\n",
    "        \"model\": model,\n",
    "        \"prompt\": final_prompt,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        response_data = response.json()\n",
    "        \n",
    "        # Extract text from Nugen response format\n",
    "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
    "            return response_data['choices'][0]['text']\n",
    "        return \"Error: No valid response content\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in run_nugen_llm: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function handles the basic communication with the AI model. Think of it as the telephone system that lets you talk to any doctor in our hospital analogy. It:\n",
    "\n",
    "    - Combines any system instructions with the user's question\n",
    "    - Sends the request to the AI service\n",
    "    - Handles the response and any potential errors\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Temperature set to 0.1 for consistent responses\n",
    "- Max tokens limited to 1000 for controlled response length\n",
    "- Basic error handling with informative messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. JSON Response Handling (JSON_nugen_llm)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSON_nugen_llm(user_prompt: str, schema: BaseModel, api_token: str, system_prompt: str = None):\n",
    "    \"\"\"\n",
    "    Makes a request to Nugen API expecting JSON response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add explicit instruction for JSON response\n",
    "        json_instruction = \"\"\"\n",
    "        IMPORTANT: Your response must be a valid JSON object matching this schema:\n",
    "        {schema}\n",
    "        \n",
    "        Respond ONLY with the JSON object, no other text.\n",
    "        \"\"\".format(schema=schema.model_json_schema())\n",
    "        \n",
    "        # Combine prompts\n",
    "        final_prompt = f\"{json_instruction}\\n\\n{system_prompt}\\n\\n{user_prompt}\" if system_prompt else f\"{json_instruction}\\n\\n{user_prompt}\"\n",
    "        \n",
    "        # Use nugen-flash-instruct for routing decisions\n",
    "        response = run_nugen_llm(\n",
    "            user_prompt=final_prompt,\n",
    "            model=\"nugen-flash-instruct\",\n",
    "            api_token=api_token\n",
    "        )\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        # First try to parse as is\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            # If that fails, try to find JSON-like structure in the text\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx != -1 and end_idx != 0:\n",
    "                json_content = response[start_idx:end_idx]\n",
    "                return json.loads(json_content)\n",
    "            raise ValueError(\"No valid JSON found in response\")\n",
    "            \n",
    "    except ValidationError as e:\n",
    "        error_message = f\"Failed to parse JSON: {e}\"\n",
    "        print(error_message)\n",
    "        # Return a default route to prevent crashes\n",
    "        return {\n",
    "            \"route\": list(model_routes.keys())[0],\n",
    "            \"reason\": \"Error in processing route selection\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in JSON_nugen_llm: {str(e)}\")\n",
    "        return {\n",
    "            \"route\": list(model_routes.keys())[0],\n",
    "            \"reason\": \"Error in processing route selection\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is like a translator that ensures all communication follows a specific format. It:\n",
    "\n",
    "- Tells the AI exactly what format to use (through schema)\n",
    "- Tries to find valid JSON even if the response isn't perfect\n",
    "- Provides fallback options if things go wrong\n",
    "\n",
    "Important Features:\n",
    "\n",
    "- Uses Pydantic for schema validation\n",
    "- Includes multiple JSON extraction attempts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. The Router Workflow (router_workflow)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_workflow(input_query: str, routes: Dict[str, str], api_token: str) -> str:\n",
    "    \"\"\"\n",
    "    Router workflow for Nugen API.\n",
    "    \"\"\"\n",
    "    ROUTER_PROMPT = \"\"\"Given a user prompt/query: {user_query}, select the best option out of the following routes:\n",
    "    {routes}. Answer only in JSON format.\"\"\"\n",
    "    \n",
    "    # Create schema for route selection\n",
    "    class Schema(BaseModel):\n",
    "        route: str = Field(..., description=\"The selected model route\")\n",
    "        reason: str = Field(\n",
    "            ...,\n",
    "            description=\"Short one-liner explanation why this route was selected for the task in the prompt/query.\"\n",
    "        )\n",
    "        \n",
    "        class Config:\n",
    "            extra = \"forbid\"\n",
    "    \n",
    "    # Call LLM to select route\n",
    "    selected_route = JSON_nugen_llm(\n",
    "        user_prompt=ROUTER_PROMPT.format(user_query=input_query, routes=routes),\n",
    "        schema=Schema,\n",
    "        api_token=api_token\n",
    "    )\n",
    "    \n",
    "    print(f\"Selected route: {selected_route['route']}\\nReason: {selected_route['reason']}\\n\")\n",
    "    \n",
    "    # Use selected model for the actual response\n",
    "    response = run_nugen_llm(\n",
    "        user_prompt=input_query,\n",
    "        model=selected_route[\"route\"],\n",
    "        api_token=api_token\n",
    "    )\n",
    "    \n",
    "    print(f\"Response: {response}\\n\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main orchestrator, like our hospital's intake system. \n",
    "\n",
    "- Takes in the user's query\n",
    "- Consults the routing model to decide which specialist (model) to use\n",
    "- Sends the query to the chosen model\n",
    "- Returns the response to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Routing Process Step by Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 1: Write a program to check if a number is prime.\n",
      "========================================\n",
      "Selected route: nugen-flash-instruct\n",
      "Reason: The prompt is asking for a general programming task, which is more suitable for a general-purpose model.\n",
      "\n",
      "Response:  A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself.\n",
      "\n",
      "## Step 1: Define the Problem and the Approach\n",
      "We need to write a program that checks if a given number is prime. A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. We will approach this by creating a function that takes an integer as input and returns a boolean value indicating whether the number is prime or not.\n",
      "\n",
      "## Step 2: Plan the Algorithm\n",
      "The algorithm will work as follows:\n",
      "- If the number is less than or equal to 1, it is not prime.\n",
      "- Check if the number has any divisors other than 1 and itself by iterating from 2 to the square root of the number.\n",
      "- If any divisor is found, the number is not prime.\n",
      "- If no divisors are found, the number is prime.\n",
      "\n",
      "## Step 3: Implement the Algorithm in Code\n",
      "Here is a simple implementation in Python:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(math.sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "# Example usage:\n",
      "number = 23\n",
      "if is_prime(number):\n",
      "    print(f\"{number} is a prime number.\")\n",
      "else:\n",
      "    print(f\"{number} is not a prime number.\")\n",
      "```\n",
      "\n",
      "## Step 4: Test the Code\n",
      "We will test the code with several numbers to ensure it works correctly for both prime and non-prime numbers.\n",
      "\n",
      "## Step 5: Refine the Code (Optional)\n",
      "For larger numbers, we might want to optimize the code further, but for most practical purposes, this implementation should suffice.\n",
      "\n",
      "The final answer is: $\\boxed{23}$\n",
      "\n",
      "\n",
      "Task 2: I had an accident what are my legal rights?\n",
      "========================================\n",
      "Selected route: llama-v3p2-3b-instruct\n",
      "Reason: The user prompt/query is related to legal rights, which is a specialized domain that the llama-v3p2-3b-instruct model is trained for.\n",
      "\n",
      "Response:  1. You have the right to be compensated for any injuries or losses you have suffered as a result of the accident. 2. You have the right to be treated with respect and dignity by the other party involved in the accident. 3. You have the right to seek legal advice from a qualified attorney who can help you navigate the legal process and protect your rights. 4. You have the accident victim's rights to seek compensation for any medical expenses, lost wages, and other related costs. 5. You have the right to report the accident to the appropriate authorities, such as the police or insurance company, and to seek their assistance in investigating the accident and determining liability. 6. You have the right to seek legal action against the other party involved in the accident, if you believe they were at fault and you have suffered damages as a result. 7. You have the right to be informed about the accident and any subsequent investigations or legal proceedings. 8. You have the right to be treated fairly and without bias by the authorities and any legal professionals involved in the case. 9. You have the right to seek compensation for any emotional distress or pain and suffering you have experienced as a result of the accident. 10. You have the legal right to sue the other party involved in the accident for damages. 11. You have the right to be represented by a qualified attorney who can help you navigate the legal process and protect your rights. 12. You have the right to seek compensation for any property damage or loss resulting from the accident. 13. You have the right to be informed about the accident and any subsequent investigations or legal proceedings in a clear and concise manner. 14. You have the right to be treated with respect and dignity by the authorities and any legal professionals involved in the case. 15. You have the right to seek compensation for any future medical expenses or lost wages resulting from the accident. 16. You have the right to report the accident to the appropriate authorities, such as the police or insurance company, and to seek their assistance in investigating the accident and determining liability. 17. You have the right to seek legal action against the other party involved in the accident, if you believe they were at fault and you have suffered damages as a result. 18. You have the right to be informed about the accident and any subsequent investigations or legal proceedings in a clear and concise manner. 19. You have the right to be treated fairly and without bias by the authorities and any legal professionals involved in the case. 20. You have the right to seek compensation for any emotional distress or pain and suffering you have experienced as a result of the accident. 21. You have the right to sue the other party involved in the accident for damages. 22. You have the right to be represented by a qualified attorney who can help you navigate the legal process and protect your rights. 23. You have the right to seek compensation for any property damage or loss resulting from the item. 24. You have the right to be informed about the accident and any subsequent investigations or legal proceedings in a clear and concise manner. 25. You have the right to be treated fairly and without bias by the authorities and any legal professionals involved in the case. 26. You have the right to seek compensation for any future medical expenses or lost wages resulting from the accident. 27. You have the right to report the accident to the appropriate authorities, such as the police or insurance company, and to seek their assistance in investigating the accident and determining liability. 28. You have the right to seek legal action against the other party involved in the accident, if you believe they were at fault and you have suffered damages as a result. 29. You have the right to be informed about the accident and any subsequent investigations or legal proceedings in a clear and concise manner. 30. You have the right to be treated fairly and without bias by the authorities and any legal professionals involved in the case. 31. You have the right to seek compensation for any emotional distress or pain and suffering you have experienced as a result of the accident. 32. You have the right to sue the other party involved in the accident for damages. 33. You have the right to be represented by a qualified attorney who can help you navigate the legal process and protect your rights. 34. You have the right to seek compensation for any property damage or loss resulting from the accident. 35. You have the right to be informed about the accident and any subsequent investigations or legal proceedings in a clear and concise manner. 36. You have the right to be treated fairly and without bias by the authorities and any legal professionals involved in the case. 37. You have the right to seek compensation for any future medical expenses or lost wages resulting from the accident. 38. You have the right to report the accident to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Model routes\n",
    "    model_routes = {\n",
    "        \"nugen-flash-instruct\": \"General purpose model for various tasks, best for creative and general queries\",\n",
    "        \"llama-v3p2-3b-instruct\": \"Specialized model for this is more specialized for legal questions and questions related to fraud, acts passed by courts, judgements, statutes, situation where legal actions are involved\"\n",
    "    }\n",
    "\n",
    "    # Example prompts\n",
    "    prompt_list = [\n",
    "        \"Write a program to check if a number is prime.\",\n",
    "        \"I had an accident what are my legal rights?\",\n",
    "    ]\n",
    "\n",
    "    # Your API token\n",
    "    api_token =  \"nugen-CnStpNdbBczk3d8SZMhmnw\"\n",
    "\n",
    "    # Process each prompt\n",
    "    for i, prompt in enumerate(prompt_list, 1):\n",
    "        print(f\"\\nTask {i}: {prompt}\")\n",
    "        print(\"=\" * 40)\n",
    "        router_workflow(prompt, model_routes, api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing Effective Routes**\n",
    "\n",
    "When defining model routes:\n",
    "\n",
    "Be specific about each model's strengths\n",
    "Include clear examples of appropriate use cases\n",
    "Define boundaries between models clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling Different Query Types**\n",
    "\n",
    "The system automatically handles:\n",
    "\n",
    "Programming questions → general purpose model\n",
    "Legal queries → legal specialist model\n",
    "Unclear cases → falls back to general model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "LLM routing is a powerful technique for getting the most out of multiple AI models. By understanding both the conceptual framework and the technical implementation, you can create robust systems that direct queries to the most appropriate model for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
