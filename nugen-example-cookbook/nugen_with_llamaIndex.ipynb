{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using Nugen's Embedding Model with LlamaIndex for PDF Content Retrieval**\n",
    "\n",
    "### **Introduction**\n",
    "In this cookbook, you will learn how to use Nugen’s powerful embedding models to convert PDF content into embeddings and how to use LlamaIndex to index and retrieve that data efficiently. This guide provides step-by-step instructions, from extracting text from PDFs to performing semantic searches using the generated embeddings.\n",
    "\n",
    "Nugen offers state-of-the-art embedding models for natural language understanding that can transform unstructured text into meaningful vectors. LlamaIndex is an efficient tool for indexing and querying text data based on semantic similarity, making it an excellent choice for creating search engines or knowledge retrieval systems.\n",
    "\n",
    "\n",
    "## Key Terms:\n",
    "\n",
    "* Embedding: A numerical representation of text, allowing machines to understand and process language in a meaningful way.\n",
    "* Nugen API: An API that provides embedding and completion models for text processing.\n",
    "* LlamaIndex: A framework for building retrieval-augmented generation (RAG) systems that index and retrieve information based on embeddings.\n",
    "* Vector Store: A data structure used to store embeddings for fast, similarity-based retrieval.\n",
    "* Semantic Search: A search method that uses the meaning of the query rather than just keyword matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up the Environment\n",
    "\n",
    "**Install Required Libraries**\n",
    "\n",
    "Before you begin, ensure you have the necessary Python libraries installed. These libraries include requests (for making HTTP requests to Nugen’s API), llama_index (for indexing and querying), and PyMuPDF (for extracting text from PDF files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\parimal\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet requests llama_index PyMuPDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get Your Nugen API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Nugen's embedding models, you will need to obtain an API key. \n",
    "You can access **Nugen API** key from **[here](https://docs.nugen.in/)** for **FREE**! \n",
    "\n",
    "Once you have the API key, store it securely, as it will be used to authenticate requests to Nugen’s API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract Text from PDF\n",
    "\n",
    "To extract the text from a PDF, we will use the PyMuPDF library (also known as fitz). It allows us to load a PDF file and extract text from each page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      " \n",
      "THE LEGAL SERVICES AUTHORITIES ACT, 1987 \n",
      "________ \n",
      "ARRANGEMENT OF SECTIONS \n",
      "________ \n",
      "CHAPTER I \n",
      "PRELIMINARY \n",
      "SECTIONS \n",
      "1. Short title, extent and commencement. \n",
      "2. Definitions. \n",
      " \n",
      "CHAPTER II \n",
      "THE NATIONAL LEGAL SERVICES AUTHORITY \n",
      "3. Constitution of the National Legal Services Authority. \n",
      "3A. Supreme Court Legal Services Committee. \n",
      "4. Functions of the Central Authority. \n",
      "5. Central Authority to work in coordination with other agencies. \n",
      " \n",
      "CHAPTER III \n",
      "STATE LEGAL SERVICES AUTHORITY \n",
      "6. C\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)  # Open the PDF file\n",
    "    text = \"\"\n",
    "    \n",
    "    # Iterate over all the pages in the PDF and extract text\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text(\"text\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage with double backslashes\n",
    "pdf_path = \"legal_service_authorities_act_1987.pdf\"\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "print(extracted_text[:500])  # Print the first 500 characters of the extracted text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split Text into Chunks\n",
    "\n",
    "To efficiently generate embeddings and avoid overwhelming the model with too much text at once, we will split the extracted text into smaller chunks (e.g., paragraphs or sections).\n",
    "\n",
    "**Split Text into Chunks Function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=50):\n",
    "    \"\"\"\n",
    "    Splits the extracted text into smaller chunks for embedding.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full text to split.\n",
    "        chunk_size (int): The maximum size of each chunk in characters.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of text chunks.\n",
    "    \"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate Embeddings from PDF Content\n",
    "\n",
    "We’ll use Nugen’s embedding model to transform the text chunks into embeddings. This will convert the textual content into numerical vectors, making it possible to perform semantic searches.\n",
    "\n",
    "**Generate Embeddings Function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_nugen_embeddings(text, model=\"nugen-flash-embed\", dimensions=123):\n",
    "    \"\"\"\n",
    "    Calls Nugen's embedding API to fetch the embeddings for the given text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to embed.\n",
    "        model (str): The embedding model name (default is \"nugen-flash-embed\").\n",
    "        dimensions (int): The number of dimensions for the embedding (default is 123).\n",
    "        \n",
    "    Returns:\n",
    "        list: Embedding vectors for the input text.\n",
    "    \"\"\"\n",
    "    url = \"https://api.nugen.in/inference/embeddings\"\n",
    "    \n",
    "    api_key = \"nugen-l9oSjm6J9rUghiHinH8d8Q\"\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": model,\n",
    "        \"dimensions\": dimensions\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",  # Replace with your Nugen API token\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        embeddings = response.json().get('embeddings')\n",
    "        return embeddings\n",
    "    else:\n",
    "        raise Exception(f\"Error fetching embeddings: {response.text}\")\n",
    "    \n",
    "\n",
    "def generate_embeddings_from_pdf(pdf_path, model=\"nugen-flash-embed\", dimensions=123):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF, splits it into chunks, and generates embeddings for each chunk.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        model (str): The embedding model name (default is \"nugen-flash-embed\").\n",
    "        dimensions (int): The number of dimensions for the embedding (default is 123).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of embedding vectors for the PDF content.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Split text into chunks\n",
    "    chunks = split_text_into_chunks(text)\n",
    "    \n",
    "    # Step 3: Generate embeddings for each chunk\n",
    "    all_embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embeddings = get_nugen_embeddings(chunk, model=model, dimensions=dimensions)\n",
    "        all_embeddings.append(embeddings)\n",
    "    \n",
    "    return all_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create a Vector Store Using LlamaIndex\n",
    "\n",
    "Next, we will index the embeddings using LlamaIndex, which allows us to efficiently store and query the embeddings based on their similarity.\n",
    "\n",
    "**Create Vector Store Function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import  VectorStoreIndex\n",
    "\n",
    "def create_vector_store(embeddings):\n",
    "    \"\"\"\n",
    "    Creates a vector store in LlamaIndex using the provided embeddings.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (list): The embedding vectors to store.\n",
    "    \n",
    "    Returns:\n",
    "        SimpleVectorStore: A vector store containing the embeddings.\n",
    "    \"\"\"\n",
    "    vector_store =  VectorStoreIndex.from_embeddings(embeddings)\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Perform Semantic Search on Indexed PDF Content\n",
    "\n",
    "Once the embeddings are indexed, we can query the vector store using a text input (query). The vector store will find the most relevant chunks based on semantic similarity.\n",
    "\n",
    "**Query Function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_store(query, vector_store, model=\"nugen-flash-embed\", dimensions=123):\n",
    "    \"\"\"\n",
    "    Queries the vector store to find the most relevant document to the input query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for in the vector store.\n",
    "        vector_store (SimpleVectorStore): The vector store containing embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        list: The most relevant documents based on the query.\n",
    "    \"\"\"\n",
    "    query_embedding = get_nugen_embeddings(query, model=model, dimensions=dimensions)\n",
    "    results = vector_store.query(query_embedding)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Putting It All Together\n",
    "\n",
    "Now we’ll combine all the functions into one cohesive process, from extracting text from the PDF to querying the indexed content.\n",
    "\n",
    "**Complete Workflow:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error fetching embeddings: {\"detail\":\"Could not validate credentials. Reason: Quota Limit Reached\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat should the Central Authority consist of?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Run the process\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf_for_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m, in \u001b[0;36mprocess_pdf_for_query\u001b[1;34m(pdf_path, query)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mProcesses a PDF by extracting text, generating embeddings, and querying the vector store.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    list: The most relevant text chunks from the PDF based on the query.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Generate embeddings from PDF and create vector store\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m create_vector_store(embeddings)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Query the vector store with the input query\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 59\u001b[0m, in \u001b[0;36mgenerate_embeddings_from_pdf\u001b[1;34m(pdf_path, model, dimensions)\u001b[0m\n\u001b[0;32m     57\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m---> 59\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_nugen_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     all_embeddings\u001b[38;5;241m.\u001b[39mappend(embeddings)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_embeddings\n",
      "Cell \u001b[1;32mIn[21], line 35\u001b[0m, in \u001b[0;36mget_nugen_embeddings\u001b[1;34m(text, model, dimensions)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching embeddings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Error fetching embeddings: {\"detail\":\"Could not validate credentials. Reason: Quota Limit Reached\"}"
     ]
    }
   ],
   "source": [
    "# Full process: from PDF extraction to query\n",
    "def process_pdf_for_query(pdf_path, query):\n",
    "    \"\"\"\n",
    "    Processes a PDF by extracting text, generating embeddings, and querying the vector store.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        query (str): The query to search for in the PDF content.\n",
    "        \n",
    "    Returns:\n",
    "        list: The most relevant text chunks from the PDF based on the query.\n",
    "    \"\"\"\n",
    "    # Generate embeddings from PDF and create vector store\n",
    "    embeddings = generate_embeddings_from_pdf(pdf_path)\n",
    "    vector_store = create_vector_store(embeddings)\n",
    "    \n",
    "    # Query the vector store with the input query\n",
    "    results = query_vector_store(query, vector_store)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Sample PDF and query\n",
    "pdf_path = \"legal_service_authorities_act_1987.pdf\"  # Replace with the actual PDF path\n",
    "query = \"What should the Central Authority consist of?\"\n",
    "\n",
    "# Run the process\n",
    "results = process_pdf_for_query(pdf_path, query)\n",
    "\n",
    "print(f\"Query Results: {results}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
