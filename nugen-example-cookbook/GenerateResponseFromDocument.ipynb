{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding Government Documents for Enhanced Query Resolution**\n",
    "**Introduction**\n",
    "\n",
    "Welcome to the Nugen API Guide! This notebook will help you use Nugen’s embedding and completion APIs to extract information from PDF documents and answer questions based on the content. \n",
    "\n",
    "By the end of this guide, you'll be able to:\n",
    "\n",
    "* Extract text from a PDF file.\n",
    "* Generate embeddings for chunks of text.\n",
    "* Find relevant information from a document using embeddings.\n",
    "* Generate answers based on the relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Installing Required Libraries**\n",
    "\n",
    "Before starting, ensure you have the necessary libraries installed. You can run the following commands to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 requests numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These libraries will help us:\n",
    "\n",
    "* PyPDF2: For extracting text from PDF documents.\n",
    "* requests: For making API calls to Nugen.\n",
    "* numpy: For handling embeddings and similarity calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Importing Libraries and Helper Functions**\n",
    "\n",
    "Let's begin by importing the libraries and defining helper functions for interacting with the Nugen API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Using Nugen APIs for Embeddings**\n",
    "\n",
    "We’ll define a function that sends text data to Nugen’s embedding model and retrieves embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nugen_embeddings(texts, model=\"nugen-flash-embed\", dimensions=768):\n",
    "    \"\"\"Fetch embeddings for a list of texts from Nugen API.\"\"\"\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  # Replace with your API key\n",
    "    embedding_url = \"https://api.nugen.in/inference/embeddings\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": model,\n",
    "        \"dimensions\": dimensions\n",
    "    }\n",
    "    \n",
    "    response = requests.post(embedding_url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return [entry[\"embedding\"] for entry in response_json[\"data\"]]\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Download PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O legal_service_authorities_act_1987.pdf https://www.indiacode.nic.in/bitstream/123456789/19023/1/legal_service_authorities_act,_1987.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the PDF document\n",
    "pdf_url = \"https://www.indiacode.nic.in/bitstream/123456789/19023/1/legal_service_authorities_act,_1987.pdf\"\n",
    "\n",
    "# Send a GET request to fetch the PDF\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "# Save the PDF to a file\n",
    "with open(\"legal_service_authorities_act_1987.pdf\", \"wb\") as pdf_file:\n",
    "    pdf_file.write(response.content)\n",
    "\n",
    "print(\"PDF downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Extracting Text from a PDF Document**\n",
    "\n",
    "The next step is to extract text from the PDF file. We’ll loop through all the pages of the PDF document and extract the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from the entire PDF document.\"\"\"\n",
    "    pdf_text = \"\"\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in reader.pages:\n",
    "            pdf_text += page.extract_text() + \"\\n\"\n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Chunking the Text**\n",
    "\n",
    "To handle large documents, it’s helpful to split the text into smaller chunks. This function breaks the extracted text into chunks of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size):\n",
    "    \"\"\"Split text into manageable chunks.\"\"\"\n",
    "    all_lines = [line for line in text.split('\\n') if line.strip()]\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(all_lines), chunk_size):\n",
    "        chunk = all_lines[i:i + chunk_size]\n",
    "        chunks.append(' '.join(chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Processing the Document and Generating Embeddings**\n",
    "\n",
    "In this step, we’ll combine everything to process the document, chunk the text, and generate embeddings for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(file_path, chunk_size=50):\n",
    "    \"\"\"Process the document, generate embeddings, and return chunks with embeddings.\"\"\"\n",
    "    pdf_text = extract_text_from_pdf(file_path)\n",
    "    chunks = chunk_text(pdf_text, chunk_size)\n",
    "    \n",
    "    doc_embeddings = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i + 1} of {len(chunks)}\")\n",
    "        doc_embds = get_nugen_embeddings([chunk], model=\"nugen-flash-embed\", dimensions=768)\n",
    "        if doc_embds:\n",
    "            doc_embeddings.extend(doc_embds)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve embeddings for chunk {i + 1}\")\n",
    "    \n",
    "    return chunks, doc_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Finding Relevant Chunks**\n",
    "\n",
    "Now, we need to find the most relevant chunk based on a query. We compare the query’s embedding with document embeddings to find the closest match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_chunk(query, chunks, doc_embeddings):\n",
    "    \"\"\"Find the most relevant chunk for the query.\"\"\"\n",
    "    query_embd = get_nugen_embeddings([query], model=\"nugen-flash-embed\", dimensions=768)\n",
    "    if query_embd:\n",
    "        query_embd = np.array(query_embd[0]).reshape(1, -1)\n",
    "        similarities = np.dot(np.array(doc_embeddings), query_embd.T).flatten()\n",
    "        retrieved_id = np.argmax(similarities)\n",
    "        if retrieved_id < len(chunks):\n",
    "            return chunks[retrieved_id]\n",
    "        else:\n",
    "            print(\"Error: Retrieved ID out of range.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Failed to retrieve query embedding.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9: Generating a Completion Based on the Relevant Chunk**\n",
    "\n",
    "After finding the relevant text chunk, we can generate an answer to the query using Nugen’s completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nugen_completion(prompt, model=\"nugen-flash-instruct\", max_tokens=400, temperature=1.0):\n",
    "    \"\"\"Fetch a completion using Nugen API.\"\"\"\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  # Replace with your API key\n",
    "    completion_url = \"https://api.nugen.in/inference/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    \n",
    "    response = requests.post(completion_url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10: Putting It All Together**\n",
    "\n",
    "We can now combine all the steps into a function that extracts text, finds relevant chunks, and generates answers for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_from_pdf(pdf_file, query):\n",
    "    \"\"\"Answer a query based on the content of the PDF file.\"\"\"\n",
    "    chunks, doc_embeddings = process_document(pdf_file, chunk_size=50)\n",
    "    relevant_text = find_relevant_chunk(query, chunks, doc_embeddings)\n",
    "    \n",
    "    if relevant_text:\n",
    "        print(\"Relevant text found:\")\n",
    "        print(relevant_text)\n",
    "        answer = get_nugen_completion(prompt=relevant_text, model=\"nugen-flash-instruct\")\n",
    "        if answer:\n",
    "            print(\"Generated answer:\", answer)\n",
    "        else:\n",
    "            print(\"Failed to generate an answer.\")\n",
    "    else:\n",
    "        print(\"No relevant text found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11: Example Usage**\n",
    "\n",
    "You can now use the following example to test the entire process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"legal_service_authorities_act_1987.pdf\"\n",
    "query = \"What should the Central Authority consist of?\"\n",
    "answer_query_from_pdf(pdf_file, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "This guide walks through how to use Nugen APIs to extract information from documents, generate embeddings, and answer queries. You can use this template to work with other PDF documents and queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
