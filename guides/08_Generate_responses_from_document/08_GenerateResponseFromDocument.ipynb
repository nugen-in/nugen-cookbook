{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention! To learn more, visit [Nugen](https://docs.nugen.in/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding Government Documents for Enhanced Query Resolution**\n",
    "**Introduction**\n",
    "\n",
    "Welcome to the Nugen API Guide! This notebook will help you use Nugen’s embedding and completion APIs to extract information from PDF documents and answer questions based on the content. \n",
    "\n",
    "By the end of this guide, you'll be able to:\n",
    "\n",
    "* Extract text from a PDF file.\n",
    "* Generate embeddings for chunks of text.\n",
    "* Find relevant information from a document using embeddings.\n",
    "* Generate answers based on the relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Installing Required Libraries**\n",
    "\n",
    "Before starting, ensure you have the necessary libraries installed. You can run the following commands to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet PyPDF2==3.0.1 requests numpy==1.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These libraries will help us:\n",
    "\n",
    "* **PyPDF2**: For extracting text from PDF documents.\n",
    "* **requests**: For making API calls to Nugen.\n",
    "* **numpy**: For handling embeddings and similarity calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Importing Libraries and Helper Functions**\n",
    "\n",
    "Let's begin by importing the libraries and defining helper functions for interacting with the Nugen API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secure API Key Management\n",
    "\n",
    "The `os.getenv(\"NUGEN_API_KEY\")` function securely retrieves the API key from environment variables, ensuring sensitive credentials are not exposed in code.\n",
    "\n",
    "create a .env file \n",
    "NUGEN_API_KEY = \"enter your key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your API key securely loaded from environment variable\n",
    "api_key = os.getenv(\"NUGEN_API_KEY\")  # Fetch API Key securely from environment variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Using Nugen APIs for Embeddings**\n",
    "\n",
    "We’ll define a function that sends text data to Nugen’s embedding model and retrieves embeddings.\n",
    "\n",
    "To read more about Nugen API and access free API keys, you can visit [Nugen Dashboard](https://nugen-platform-frontend.azurewebsites.net/dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    \"\"\"Sanitize text by removing any non-printable/control characters.\"\"\"\n",
    "    sanitized = ''.join([char for char in text if char.isprintable()])\n",
    "    return sanitized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Sanitization\n",
    "\n",
    "The `sanitize_text` function removes non-printable or control characters from a string, ensuring clean and readable text for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nugen_embeddings(texts, model=\"nugen-flash-embed\", dimensions=768):\n",
    "    \"\"\"Fetch embeddings for a list of texts from Nugen API.\"\"\"\n",
    "      # Replace with your API key\n",
    "    embedding_url = \"https://api.nugen.in/inference/embeddings\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": model,\n",
    "        \"dimensions\": dimensions\n",
    "    }\n",
    "    \n",
    "    response = requests.post(embedding_url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return [entry[\"embedding\"] for entry in response_json[\"data\"]]\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Download PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O legal_service_authorities_act_1987.pdf https://www.indiacode.nic.in/bitstream/123456789/19023/1/legal_service_authorities_act,_1987.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Type Validation\n",
    "\n",
    "This code ensures security by verifying that only PDF files are downloaded. It raises an error if the file extension is not `.pdf`, preventing potential risks from unauthorized file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --------------------- SECURITY CONTRIBUTION File Type Check ---------------------\n",
    "# Download PDF from a trusted source\n",
    "pdf_url = \"https://www.indiacode.nic.in/bitstream/123456789/13236/1/the_registration_act,_1908.pdf\"\n",
    "response = requests.get(pdf_url)\n",
    "pdf_file = \"registration_act_1908.pdf\"\n",
    "if not pdf_file.lower().endswith(\".pdf\"):\n",
    "    raise ValueError(\" Only PDF files are allowed.\")\n",
    "with open(pdf_file, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"PDF downloaded and verified as safe.\")\n",
    "# --------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Extracting Text from a PDF Document**\n",
    "\n",
    "The next step is to extract text from the PDF file. We’ll loop through all the pages of the PDF document and extract the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from the entire PDF document with safety check.\"\"\"\n",
    "    pdf_text = \"\"\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:  # SECURITY: Only add if not None\n",
    "                pdf_text += text + \"\\n\"\n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Text Extraction with Safety Check\n",
    "\n",
    "The `extract_text_from_pdf` function reads and extracts text from each page of a PDF file. It ensures safety by only appending non-`None` values, preventing issues from invalid or empty page content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Chunking the Text**\n",
    "\n",
    "To handle large documents, it’s helpful to split the text into smaller chunks. This function breaks the extracted text into chunks of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Sentence-based chunking for better coherence\n",
    "def chunk_text(text, chunk_size=50):\n",
    "    \"\"\"Split text into semi-coherent sentence-based chunks.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "    chunks, chunk = [], []\n",
    "    for sentence in sentences:\n",
    "        chunk.append(sentence)\n",
    "        if len(chunk) >= chunk_size:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = []\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text):\n",
    "    \"\"\"Estimate token count based on word count.\"\"\"\n",
    "    return len(text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-Based Chunking for Better Coherence\n",
    "\n",
    "The `chunk_text` function splits text into logical chunks based on sentences, ensuring readability and coherence. By grouping sentences and using a specified chunk size, this approach improves text segmentation compared to random word-based chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Processing the Document and Generating Embeddings**\n",
    "\n",
    "In this step, we’ll combine everything to process the document, chunk the text, and generate embeddings for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(file_path, chunk_size=50):\n",
    "    \"\"\"Process the document, generate embeddings, and return chunks with embeddings.\"\"\"\n",
    "    pdf_text = extract_text_from_pdf(file_path)\n",
    "    pdf_text = sanitize_text(pdf_text)  # Sanitize input text to ensure it's clean\n",
    "    chunks = chunk_text(pdf_text, chunk_size)\n",
    "    doc_embeddings = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i + 1} of {len(chunks)}\")\n",
    "        doc_embds = get_nugen_embeddings([chunk], model=\"nugen-flash-embed\", dimensions=768)\n",
    "        if doc_embds:\n",
    "            doc_embeddings.extend(doc_embds)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve embeddings for chunk {i + 1}\")\n",
    "    return chunks, doc_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Processing with Embedding Generation\n",
    "\n",
    "The `process_document` function processes a PDF file by extracting its text, sanitizing it, chunking it into manageable pieces, and generating embeddings for each chunk. \n",
    "\n",
    "- **Text Extraction**: Reads the entire content of the PDF using `extract_text_from_pdf`.\n",
    "- **Sanitization**: Cleans the text by removing non-printable characters with `sanitize_text`.\n",
    "- **Chunking**: Splits the sanitized text into logical sections using `chunk_text`, ensuring each chunk is coherent and adheres to the specified size.\n",
    "- **Embedding Generation**: Iterates over the chunks, generating embeddings using the Nugen API (`get_nugen_embeddings`). Each embedding is stored in the `doc_embeddings` list.\n",
    "- **Error Handling**: Logs a message for chunks where embedding generation fails.\n",
    "- **Output**: Returns the processed chunks and their corresponding embeddings.\n",
    "\n",
    "This function streamlines document preparation and embedding creation, making it ready for retrieval or further NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Finding Relevant Chunks**\n",
    "\n",
    "### Finding Relevant Chunks Using Query Embeddings\n",
    "\n",
    "The `find_relevant_chunk` function identifies the most relevant text chunk based on a query by calculating cosine similarity between the query's embedding and document embeddings. It retrieves the chunk with the highest similarity and includes safeguards to handle errors like missing embeddings or out-of-range IDs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_chunk(query, chunks, doc_embeddings):\n",
    "    \"\"\"Find the most relevant chunk for the query.\"\"\"\n",
    "    query_embd = get_nugen_embeddings([query], model=\"nugen-flash-embed\", dimensions=768)\n",
    "    if query_embd:\n",
    "        query_embd = np.array(query_embd[0]).reshape(1, -1)\n",
    "        similarities = np.dot(np.array(doc_embeddings), query_embd.T).flatten()\n",
    "        retrieved_id = np.argmax(similarities)\n",
    "        if retrieved_id < len(chunks):\n",
    "            print(f\" Most relevant chunk (similarity: {similarities[retrieved_id]:.4f}):\\n\")\n",
    "            return chunks[retrieved_id]\n",
    "        else:\n",
    "            print(\" Error: Retrieved ID out of range.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\" Failed to retrieve query embedding.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9: Generating a Completion Based on the Relevant Chunk**\n",
    "\n",
    "After finding the relevant text chunk, we can generate an answer to the query using Nugen’s completion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nugen_completion(prompt, model=\"nugen-flash-instruct\", max_tokens=400, temperature=1.0):\n",
    "    \"\"\"Fetch a completion using Nugen API.\"\"\"\n",
    "    completion_url = \"https://api.nugen.in/inference/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    \n",
    "    response = requests.post(completion_url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging Q&A Pairs for Auditing\n",
    "#The `log_qa` function records question-and-answer pairs to a log file (`qna_log.txt`) with timestamps, facilitating auditing and tracking. By appending each entry with the current timestamp, it ensures chronological logging for transparency and debugging.\n",
    "def log_qa(question, answer):\n",
    "    \"\"\"Log Q&A pairs to a file with timestamps for auditing.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(\"qna_log.txt\", \"a\") as log_file:\n",
    "        log_file.write(f\"{timestamp} - Question: {question}\\nAnswer: {answer}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10: Putting It All Together**\n",
    "\n",
    "We can now combine all the steps into a function that extracts text, finds relevant chunks, and generates answers for a given query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query-Based PDF Analysis and Answer Generation\n",
    "\n",
    "The `answer_query_from_pdf` function processes a PDF file and answers a user query by extracting relevant content and using an AI model for completion:\n",
    "\n",
    "1. **Document Processing**:\n",
    "   - Extracts and sanitizes text from the PDF.\n",
    "   - Splits the text into coherent chunks and generates embeddings for those chunks.\n",
    "\n",
    "2. **Chunk Retrieval**:\n",
    "   - Identifies the most relevant chunk of text based on the query using similarity calculations.\n",
    "\n",
    "3. **AI Completion**:\n",
    "   - Sends the relevant chunk as a prompt to an AI model (`nugen-flash-instruct`) for generating a response.\n",
    "\n",
    "4. **Logging**:\n",
    "   - Logs the question-and-answer pair with a timestamp for auditing purposes.\n",
    "\n",
    "5. **Error Handling**:\n",
    "   - Displays appropriate messages if relevant text or an AI-generated answer is unavailable.\n",
    "\n",
    "This function integrates multiple steps to streamline the process of answering queries using PDF content while ensuring robust error management and audit logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_from_pdf(pdf_file, query):\n",
    "    \"\"\"Answer a query based on the content of the PDF file.\"\"\"\n",
    "    chunks, doc_embeddings = process_document(pdf_file, chunk_size=50)\n",
    "    relevant_text = find_relevant_chunk(query, chunks, doc_embeddings)\n",
    "    if relevant_text:\n",
    "        print(\"Relevant text found:\")\n",
    "        print(relevant_text)\n",
    "        answer = get_nugen_completion(prompt=relevant_text, model=\"nugen-flash-instruct\")\n",
    "        if answer:\n",
    "            print(\"Generated answer:\", answer)\n",
    "            log_qa(query, answer)  # Log Q&A pair with timestamp\n",
    "        else:\n",
    "            print(\"Failed to generate an answer.\")\n",
    "    else:\n",
    "        print(\"No relevant text found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 11: Example Usage**\n",
    "\n",
    "You can now use the following example to test the entire process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 23\n",
      "Processing chunk 2 of 23\n",
      "Processing chunk 3 of 23\n",
      "Processing chunk 4 of 23\n",
      "Processing chunk 5 of 23\n",
      "Processing chunk 6 of 23\n",
      "Processing chunk 7 of 23\n",
      "Processing chunk 8 of 23\n",
      "Processing chunk 9 of 23\n",
      "Processing chunk 10 of 23\n",
      "Processing chunk 11 of 23\n",
      "Processing chunk 12 of 23\n",
      "Processing chunk 13 of 23\n",
      "Processing chunk 14 of 23\n",
      "Processing chunk 15 of 23\n",
      "Processing chunk 16 of 23\n",
      "Processing chunk 17 of 23\n",
      "Processing chunk 18 of 23\n",
      "Processing chunk 19 of 23\n",
      "Processing chunk 20 of 23\n",
      "Processing chunk 21 of 23\n",
      "Processing chunk 22 of 23\n",
      "Processing chunk 23 of 23\n",
      "Relevant text found:\n",
      " (2) The Registrar shall also forward a copy of such document, together with a copy of the map or plan  (if any) mentioned in section 21, to every other Registrar in whose district any part of such property is  situate.   (3) Such Registrar on receiving any such copy s hall file it in his Book No. 1, and shall also send a  memorandum of the copy to each of the Sub -Registrars subordinate to him within whose sub -district any  part of the property is situate.   (4) Every Sub -Registrar receiving any memorandum under this section  shall file it in his Book No. 1.   67. [Procedure after registration under section 30, sub -section  (2).] Omitted by the Registration and  Other Related Laws  (Amendment ) Act, 2001 (48 of 2001), s. 8 (w.e.f . 24-9-2001).   (E) Of the Controlling powers of Registrar and Inspector -General   68. Power of Registrar to superintend and control Sub -Registrars .—(1) Every Sub -Registrar  shall perform the duties of his office under the superintendence and control of the Registrar in whose  district the office of such Sub -Registrar is situate.   (2) Every Registrar shall have authority to issue (whether on complaint or otherwise) any order  consistent with this Act which he considers necessary in respect of any act or omission of any Sub - Registrar subordinate to him or in res pect of the rectification of any error regarding the book or the office  in which any document has been registered.   69. Power of Inspector -General to superintend registration offices and  make rules .—(1) The  Inspector -General shall exercise a general superintendence over all the registration offices in the  territories under the  1[State Government], and shall have power from time to time to make rule s consistent  with this Act —  (a) providing for the safe custody of  books , papers and  documents ; 2***  3[(aa) providing the manner in which and the safeguards subject to which the books may be kept  in computer floppies or diskettes or in any other electronic form under sub -section ( 1) of section  16A;]   (b) declaring  what language shall be deemed to be commonly used in each  district ;  (c) declaring what territorial divisions shall be recognized under section 21;   (d) regulating the amount of fines imposed under sections 25 and 34, respectively;   (e) regulating the exerci se of the discretion reposed in the registering officer by section 63;   (f) regulating the form in which registering officers are to make memoranda of documents;   (g) regulating the authentication by Registrars and Sub -Registrars of the books kept in their  respective offices under section 51;   4[(gg) regulating the manner in which the instruments referred to in sub -section ( 2) of section 88  may be presented for registration;]   (h) declaring the particulars to be contained in Indexes Nos. I, II, III and IV, resp ectively;   (i) declaring the holidays that shall be observed in the registration offices; and   (j) generally, regulating the proceedings of the Registrars and Sub -Registrars.   (2) The rules so made shall be submitted to the  1[State Government] for approval, and, after they have  been approved, they shall be published in the  5[Official Gazette], and on publication shall have effect as if  enacted in this Act.   1. Subs. by the A.O. 1950, for \"Provincial Government\".   2. The words “ and also for the destru ction  of such books, papers a nd documents as need no longer be kept ”  rep. by Act 5 of  1917, s. 6 and the Schedule .  3. Ins. by Act 48 of 2001, s.  9 (w.e.f. 24 -9-2001).   4. Ins. by Act 39 of 1948, s.  4.  5. Subs . by the A.O. 1937, for “Local Official Gazette ”.  20   70. Power of Inspector -General to remit fines .—The Inspector -General may also, in the exercise of  his discretion, remit wholly or in part the difference between any fine levied under section 25 or section  34, and the amount of the proper  registration  fee. \n",
      "Generated answer: 71. Power of Inspector -General to excuse delay .—The Inspector -General may, in the exercise of his  discretion, excuse the delay of any Sub -Registrar in presenting any return or account required by  section 82, or of any registering officer in making any entry or endorsement required by section 52,  and may also condone the delay of any person in presenting any instrument for registration under  section 23.   (F) Of the duties and powers of registering officers   72. Registering officer to attend at office .—Every registering officer shall attend at his office at such  hours, and on such days, as the Inspector -General directs, and shall perform the duties of his office  during such attendance.   73. Registering officer to affix signature and seal .—Every registering officer shall affix his signature  and official seal to all documents admitted or rejected by him as worthy of registration, and to all  certificates of registration granted by him, and shall subscribe his name and affix his official seal to all  attestation made by him under section 58.   74. Registering officer to prepare and maintain all books and indexes .—Every registering officer  shall prepare and maintain all such books and indexes as are prescribed by sections 17, 18 and 19, and  shall make in such books and indexes all such entries, and shall perform all such duties, as are  prescribed by any other provision of this Act.   75. Registering officer to make endorsements and entries .—Every registering officer shall make the  endorsements and entries, and shall grant the certificates, prescribed by sections 52, 58, 60 and 61.   76. Registering officer to issue certificate of registration .—Every registering officer shall, on  registration of any document, give a certificate of registration under his signature and official seal.   77. Registering officer to issue certified copies .—Every\n"
     ]
    }
   ],
   "source": [
    "pdf_file = \"registration_act_1908.pdf\"\n",
    "query = \"What is the information regarding  Offices of Registrar and Sub-Registrar?\"\n",
    "answer_query_from_pdf(pdf_file, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "This guide walks through how to use Nugen APIs to extract information from documents, generate embeddings, and answer queries. You can use this template to work with other PDF documents and queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
