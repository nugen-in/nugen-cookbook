{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Nugen Intelligence**\n",
    "<img src=\"https://nugen.in/logo.png\" alt=\"Nugen Logo\" width=\"200\"/>\n",
    "\n",
    "Domain-aligned foundational models at industry leading speeds and zero-data retention! To learn more, visit [Nugen](https://docs.nugen.in/introduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nugen APIs with LlamaIndex** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Introduction: What are Completion Models?**\n",
    "\n",
    "Completion models are AI models that generate text based on an input prompt. These models are designed to \"complete\" a given sentence, idea, or any form of text. For example, if you provide the prompt \"The sky is\", the completion model might respond with \"blue and vast on a sunny day.\" Completion models are widely used in chatbots, automated content generation, coding assistants, and much more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cookbook, we’ll explore how to use **Nugen's** powerful completion models via their API and how we can integrate them with the **LlamaIndex** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Getting Started with Nugen Completion Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nugen provides powerful AI models through its API for various tasks, including text completion. To get started with Nugen, follow these steps:\n",
    "\n",
    "**Step 1: Get Access to Nugen APIs**\n",
    "\n",
    "To use Nugen's models, you need an API key. You can access Nugen API key from [here](https://docs.nugen.in/) for FREE! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Install required libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install llama-index requests llama-index-llms-openllm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Example of Nugen Completion Model API Call**\n",
    "\n",
    "Now that you have your API key, let's make an API request to Nugen's completion endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'nugen-1731761084.944839', 'object': 'text_completion', 'created': 1731761084.944839, 'model': 'nugen-flash-instruct', 'choices': [{'text': ' gray and overcast, with a misty rain that’s more like a gentle drizzle than a downpour. The sun is hiding behind the clouds, but the temperature is mild, and the air is filled with the sweet scent of blooming flowers.\\nI take a deep breath, feeling the cool mist on my face, and listen to the soothing sound of raindrops hitting the pavement. It’s a peaceful morning, one that invites contemplation and introspection.\\nAs I walk through the quiet streets, I notice the way the rain brings out the vibrant colors of the flowers and trees. The petals seem to glow with an inner light, and the leaves shimmer with dew. The world feels fresh and new, full of possibility.\\nI think about the way the rain can wash away worries and troubles, leaving us feeling clean and renewed. It’s a reminder that life is full of cycles and seasons, and that every storm will eventually pass.\\nAs I continue my walk, I come across a small pond, its surface reflecting the gray sky above. The water is calm and still, with only the occasional ripple disturbing its tranquility. I sit down on a nearby bench, watching the rain create tiny circles on the pond’s surface.\\nIn the stillness, I feel my mind begin to quiet, my thoughts untangling like the threads of a knot. I breathe in the peacefulness of the moment, feeling my heart fill with gratitude for this beautiful, rainy day.\\nAs I sit there, I realize that the rain is not just a weather phenomenon, but a metaphor for life itself. It reminds us to slow down, to appreciate the beauty in the everyday, and to find peace in the midst of turmoil.\\nThe rain may not be the most glamorous or exciting weather, but it has a way of soothing the soul. And as I sit here, surrounded by the gentle patter of raindrops, I feel my heart fill with a sense of calm and contentment. It’s a feeling that I know', 'index': 0, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 4, 'completion_tokens': 400, 'total_tokens': 404}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Nugen API endpoint for text completions\n",
    "url = \"https://api.nugen.in/inference/completions\"\n",
    "nugen_api_key = \"nugen-CnStpNdbBczk3d8SZMhmnw\"\n",
    "\n",
    "# Prepare the request payload\n",
    "payload = {\n",
    "    \"model\": \"nugen-flash-instruct\",  # The model to use\n",
    "    \"prompt\": \"The sky is\",  # Prompt to generate text for\n",
    "    \"max_tokens\": 400,  # Limit for the number of tokens in the output\n",
    "    \"temperature\": 1  # Controls creativity in the output\n",
    "}\n",
    "\n",
    "# Include your API key\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {nugen_api_key}\",  # Replace with your actual API key\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Send the request to Nugen API\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# Print the response from Nugen API\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details of the API Parameters:**\n",
    "\n",
    "* Model: Specifies which model you are using, such as \"nugen-flash-instruct\".\n",
    "* Prompt: The input text you want to complete.\n",
    "* Max Tokens: The maximum number of tokens (words or symbols) the model should generate.\n",
    "* Temperature: Affects the randomness of the model's output. A lower value like 0.1 will make the output more deterministic, while a higher value like 1.0 will allow for more creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is LlamaIndex? Using Nugen with LlamaIndex**\n",
    "\n",
    "LlamaIndex (formerly known as GPT Index) is a framework that provides easy access to language models like GPT, and it allows you to integrate various LLMs into your applications with minimal setup.\n",
    "\n",
    "**How to Use Nugen with LlamaIndex**\n",
    "\n",
    "To integrate Nugen’s API with LlamaIndex, you can use the OpenLLM class, which acts as an interface to connect LlamaIndex with different language models, including Nugen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Configure LlamaIndex with Nugen API:**\n",
    "\n",
    "Here's a simple example of how to configure LlamaIndex to use Nugen’s completion model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from llama_index.llms.openllm import OpenLLM\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "# Set up the Nugen model with LlamaIndex\n",
    "llm = OpenLLM(\n",
    "    model=\"nugen-flash-instruct\",  # Nugen model name\n",
    "    api_base=\"https://api.nugen.in/inference/\",  # Nugen's API base URL\n",
    "    api_key=nugen_api_key,  # Your API key\n",
    "    max_tokens=1000  # Max token limit for completion\n",
    ")\n",
    "\n",
    "# Test the model with a sample prompt\n",
    "completion_response = llm.complete(\"To infinity, and\")\n",
    "print(completion_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of Parameters:**\n",
    "\n",
    "* model: The Nugen model to use (nugen-flash-instruct).\n",
    "* api_base: Base URL for the Nugen API.\n",
    "* api_key: Your Nugen API key for authentication.\n",
    "* max_tokens: Defines how much text the model should generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Code:**\n",
    "\n",
    "Once set up, you can interact with the Nugen model through LlamaIndex, providing prompts and receiving text completions just like in the example above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "In this guide, we explored how to use Nugen’s completion models both directly through API calls and by integrating them with the LlamaIndex framework. Nugen’s models provide high-quality text generation capabilities, which, when paired with LlamaIndex, can streamline interactions with LLMs for various tasks.\n",
    "\n",
    "By following this cookbook, junior and beginner developers should now be able to:\n",
    "\n",
    "* Understand the basics of completion models.\n",
    "* Get started with Nugen APIs, including setting up API keys and making requests.\n",
    "* Use LlamaIndex to integrate Nugen models seamlessly into their applications.\n",
    "* You are now equipped to build your own applications using Nugen and LlamaIndex!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
